package main

import (
	"encoding/json"
	"fmt"
	"log"
	"math"
	"os"
	"path/filepath"

	"song-recognition/drone"
	"song-recognition/utils"
	"song-recognition/wav"
)

// Explain WHY you're getting the confidence scores you see
func main() {
	if len(os.Args) < 2 {
		log.Fatal("Usage: go run main.go <audio-file.wav>")
	}

	testFile := os.Args[1]
	fmt.Printf("=== Explaining Classification for: %s ===\n\n", filepath.Base(testFile))

	// Load prototypes to show what we're working with
	modelPath := utils.GetEnv("DRONE_MODEL_PATH", filepath.Join("drone", "prototypes.json"))
	data, err := os.ReadFile(modelPath)
	if err != nil {
		log.Fatalf("Failed to read prototypes: %v", err)
	}

	var prototypes []drone.Prototype
	if err := json.Unmarshal(data, &prototypes); err != nil {
		log.Fatalf("Failed to parse prototypes: %v", err)
	}

	fmt.Printf("üìä Dataset Overview:\n")
	labelCounts := make(map[string]int)
	for _, p := range prototypes {
		labelCounts[p.Label]++
	}
	fmt.Printf("   Total prototypes: %d\n", len(prototypes))
	for label, count := range labelCounts {
		fmt.Printf("   - %s: %d samples\n", label, count)
	}
	fmt.Printf("\n‚ö†Ô∏è  This is a VERY small dataset. You need 20-50 samples per class!\n\n")

	// Load classifier
	k := 3
	classifier, err := drone.NewClassifierFromFile(modelPath, k)
	if err != nil {
		log.Fatalf("Failed to load classifier: %v", err)
	}

	// Extract features from test file
	convertedPath, err := wav.ConvertToWAV(testFile, 1)
	if err != nil {
		log.Fatalf("Convert error: %v", err)
	}
	defer func() {
		if convertedPath != testFile {
			os.Remove(convertedPath)
		}
	}()

	wavInfo, err := wav.ReadWavInfo(convertedPath)
	if err != nil {
		log.Fatalf("Read error: %v", err)
	}

	samples, err := wav.WavBytesToSamples(wavInfo.Data)
	if err != nil {
		log.Fatalf("Decode error: %v", err)
	}

	preprocessCfg := drone.DefaultPreprocessingConfig()
	processed := drone.PreprocessAudio(samples, wavInfo.SampleRate, preprocessCfg)

	features, err := drone.ExtractFeatureVector(processed, wavInfo.SampleRate)
	if err != nil {
		log.Fatalf("Feature extraction error: %v", err)
	}

	fmt.Printf("üîç Extracted Features (first 5):\n")
	featureNames := []string{"Energy", "ZCR", "Centroid", "Bandwidth", "Rolloff"}
	for i := 0; i < 5 && i < len(features); i++ {
		fmt.Printf("   %d. %-12s: %.6f\n", i+1, featureNames[i], features[i])
	}
	fmt.Println()

	// Classify
	predictions, err := classifier.Predict(features)
	if err != nil {
		log.Fatalf("Classification error: %v", err)
	}

	if len(predictions) == 0 {
		log.Fatal("No predictions returned")
	}

	fmt.Printf("üéØ Classification Results:\n")
	for i, pred := range predictions {
		emoji := "  "
		if i == 0 && pred.Confidence >= 0.90 {
			emoji = "‚úÖ"
		} else if i == 0 && pred.Confidence >= 0.70 {
			emoji = "‚ö†Ô∏è"
		} else if i == 0 {
			emoji = "‚ùå"
		}

		fmt.Printf("   %s #%d: %s\n", emoji, i+1, pred.Label)
		fmt.Printf("      Confidence: %.1f%%\n", pred.Confidence*100)
		fmt.Printf("      Avg Distance: %.4f\n", pred.AverageDist)
		fmt.Printf("      Support: %d prototypes (out of k=%d neighbors)\n", pred.Support, k)
	}
	fmt.Println()

	// Explain WHY we got this result
	topPred := predictions[0]
	fmt.Printf("üí° Why %.1f%% confidence for '%s'?\n\n", topPred.Confidence*100, topPred.Label)

	if topPred.Support == k {
		fmt.Printf("   ‚úÖ All %d nearest neighbors are '%s'\n", k, topPred.Label)
		fmt.Printf("      This is the best possible result with k=%d!\n", k)
	} else if len(predictions) == 1 {
		fmt.Printf("   ‚úÖ All %d nearest neighbors have the same label\n", k)
		fmt.Printf("      Confidence = 100%% (no competition)\n")
	} else {
		fmt.Printf("   ‚ö†Ô∏è  The %d nearest neighbors are split:\n", k)
		for _, pred := range predictions {
			percentage := float64(pred.Support) / float64(k) * 100
			fmt.Printf("      - %d/%d (%.0f%%) are '%s'\n", pred.Support, k, percentage, pred.Label)
		}
		fmt.Printf("\n   This means your test sample is roughly %.0f%% similar to '%s'\n",
			topPred.Confidence*100, topPred.Label)
		fmt.Printf("   and %.0f%% similar to other classes.\n",
			(1-topPred.Confidence)*100)
	}

	fmt.Println()
	fmt.Printf("üìè Closest Prototypes:\n")
	if len(topPred.TopPrototypes) == 0 {
		fmt.Println("   (none)")
	} else {
		for i, ps := range topPred.TopPrototypes {
			if i >= 5 {
				break
			}
			matchedProto := findProtoByID(prototypes, ps.ID)
			fmt.Printf("   %d. %s (label: %s)\n", i+1, ps.ID, matchedProto.Label)
			fmt.Printf("      Distance: %.4f (weight: %.2f)\n", ps.Distance, ps.Weight)
			fmt.Printf("      Source: %s\n", filepath.Base(matchedProto.Source))

			// Explain distance
			if ps.Distance < 0.1 {
				fmt.Printf("      ‚úÖ Very close match!\n")
			} else if ps.Distance < 0.5 {
				fmt.Printf("      ‚úÖ Good match\n")
			} else if ps.Distance < 1.0 {
				fmt.Printf("      ‚ö†Ô∏è  Moderate similarity\n")
			} else {
				fmt.Printf("      ‚ùå Distant match\n")
			}
		}
	}

	fmt.Println()
	fmt.Printf("üßÆ Understanding the Math:\n")
	fmt.Printf("   1. Your test sample has 19 features\n")
	fmt.Printf("   2. Each prototype also has 19 features\n")
	fmt.Printf("   3. Distance = how different the features are\n")
	fmt.Printf("   4. Weight = 1 / distance (closer = higher weight)\n")
	fmt.Printf("   5. Confidence = sum(weights for label) / sum(all weights)\n")
	fmt.Printf("\n   With only %d prototypes:\n", len(prototypes))
	fmt.Printf("   - Each prototype has huge influence on results\n")
	fmt.Printf("   - Adding ONE new sample changes everything\n")
	fmt.Printf("   - Feature scaler statistics are unstable\n")
	fmt.Printf("   - You need 10-20x more data for reliable results\n")

	fmt.Println()
	fmt.Printf("üìà What Would Help:\n")
	if topPred.Confidence < 0.70 {
		fmt.Printf("   ‚ùå Low confidence (< 70%%) means:\n")
		fmt.Printf("      - Test sample is ambiguous\n")
		fmt.Printf("      - OR: Not enough training examples\n")
		fmt.Printf("      - OR: Features don't discriminate well\n")
		fmt.Printf("\n   ‚úÖ Solutions:\n")
		fmt.Printf("      1. Add 10-20 more samples of '%s'\n", topPred.Label)
		fmt.Printf("      2. Add 20-30 'noise' samples (currently: 0)\n")
		fmt.Printf("      3. Verify your features capture drone characteristics\n")
	} else if topPred.Confidence < 0.90 {
		fmt.Printf("   ‚ö†Ô∏è  Moderate confidence (70-90%%) means:\n")
		fmt.Printf("      - Classifier is working but uncertain\n")
		fmt.Printf("      - Some neighbors belong to other classes\n")
		fmt.Printf("\n   ‚úÖ This would improve with:\n")
		fmt.Printf("      - 5-10 more samples per class\n")
		fmt.Printf("      - Better class balance (currently uneven)\n")
	} else {
		fmt.Printf("   ‚úÖ High confidence (> 90%%) - good!\n")
		fmt.Printf("      This is as good as it gets with %d samples\n", len(prototypes))
		fmt.Printf("\n   To maintain this accuracy:\n")
		fmt.Printf("      - Test with more diverse audio\n")
		fmt.Printf("      - Add edge cases to training data\n")
	}

	fmt.Println()
	fmt.Printf("üéì Key Takeaway:\n")
	fmt.Printf("   Your classifier IS working correctly!\n")
	fmt.Printf("   The 'random' results are because:\n")
	fmt.Printf("   1. Only %d training samples (need 50-100+)\n", len(prototypes))
	fmt.Printf("   2. No negative examples (everything is 'drone')\n")
	fmt.Printf("   3. Class imbalance (%s: %d, others: varies)\n",
		topPred.Label, labelCounts[topPred.Label])
	fmt.Printf("\n   KNN is fine. Features are fine. Algorithm is fine.\n")
	fmt.Printf("   YOU NEED MORE DATA! üéØ\n")
}

func findProtoByID(prototypes []drone.Prototype, id string) drone.Prototype {
	for _, p := range prototypes {
		if p.ID == id {
			return p
		}
	}
	return drone.Prototype{ID: id, Label: "unknown", Source: "not found"}
}

func cosineSimilarity(a, b []float64) float64 {
	var dotProduct, normA, normB float64
	for i := 0; i < len(a) && i < len(b); i++ {
		dotProduct += a[i] * b[i]
		normA += a[i] * a[i]
		normB += b[i] * b[i]
	}
	if normA == 0 || normB == 0 {
		return 0
	}
	return dotProduct / (math.Sqrt(normA) * math.Sqrt(normB))
}
